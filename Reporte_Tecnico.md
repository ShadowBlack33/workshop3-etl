# Workshop 3 â€“ End-to-End Architecture & Model Evaluation ğŸ“Š

**Caso de uso:** PredicciÃ³n y anÃ¡lisis del `Happiness Score` (World Happiness Report 2015â€“2019) usando un pipeline completo:

**ETL â†’ EDA â†’ Entrenamiento de modelo â†’ Kafka Streaming â†’ Consumer con modelo â†’ Data Warehouse en PostgreSQL â†’ Dashboard en Power BI**

Este documento describe en detalle:

- Los datasets utilizados.
- La lÃ³gica de ETL y el anÃ¡lisis exploratorio.
- El modelo seleccionado y cÃ³mo se entrena.
- La arquitectura de streaming con Kafka.
- La estructura del Data Warehouse (`predictions` en PostgreSQL).
- CÃ³mo todo se integra para evaluaciÃ³n y visualizaciÃ³n.

---

## 1. TecnologÃ­as y herramientas âš™ï¸

Este proyecto estÃ¡ diseÃ±ado como un mini ecosistema de datos moderno:

- ğŸ **Python 3**  
  Lenguaje principal para ETL, entrenamiento, streaming y conexiÃ³n a la base de datos.

- ğŸ““ **Jupyter Notebooks**
  - `notebooks/EDA.ipynb`: anÃ¡lisis exploratorio de datos.
  - `notebooks/ModelTraining.ipynb`: experimentos con el modelo antes de consolidar en scripts.

- ğŸ” **Apache Kafka**
  - Canal de streaming para enviar fila por fila los registros ya transformados.
  - Topic principal: `happiness_features`.

- ğŸ˜ **PostgreSQL**
  - Se usa como **Data Warehouse**.
  - Guarda la tabla final `predictions` con:
    - Features
    - Valor real (`y_true`)
    - PredicciÃ³n (`y_pred`)
    - Flags de si fue train/test

- ğŸ³ **Docker / docker-compose**
  - Orquesta servicios de:
    - Kafka
    - Zookeeper
    - PostgreSQL

- ğŸ§© **Visual Studio Code**
  - Editor principal del proyecto.
  - Extensiones clave:
    - Python
    - Jupyter
    - SQLTools + SQLTools PostgreSQL Driver (para inspeccionar la base desde VS Code).

- ğŸ“Š **Power BI Desktop**
  - Herramienta de visualizaciÃ³n para construir el dashboard final consumiendo directamente de PostgreSQL.

- ğŸ“¦ **scikit-learn**
  - LibrerÃ­a usada para entrenar el modelo de regresiÃ³n lineal.

---

## 2. Estructura del repositorio ğŸ“

La estructura estÃ¡ pensada para separar claramente responsabilidades:

```text
.
â”œâ”€ data/
â”‚  â”œâ”€ 2015.csv
â”‚  â”œâ”€ 2016.csv
â”‚  â”œâ”€ 2017.csv
â”‚  â”œâ”€ 2018.csv
â”‚  â””â”€ 2019.csv
â”‚     # Archivos originales del World Happiness Report.
â”‚
â”œâ”€ db/
â”‚  â””â”€ pgdata/
â”‚     # Volumen de datos de PostgreSQL (montado por Docker).
â”‚
â”œâ”€ docs/
â”‚  â”œâ”€ REPORT.md
â”‚     # Este documento tÃ©cnico.
â”‚
â”œâ”€ kafka/
â”‚  â”œâ”€ producer.py
â”‚  â”‚   # Lee los CSV, aplica ETL, marca train/test, envÃ­a registros a Kafka.
â”‚  â””â”€ consumer.py
â”‚      # Lee desde Kafka, aplica modelo, guarda en PostgreSQL (tabla predictions).
â”‚
â”œâ”€ model/
â”‚  â””â”€ happiness_model.pkl
â”‚     # Modelo entrenado (LinearRegression) serializado.
â”‚
â”œâ”€ notebooks/
â”‚  â”œâ”€ EDA.ipynb
â”‚  â”‚   # ExploraciÃ³n, unificaciÃ³n de columnas, anÃ¡lisis estadÃ­stico y visualizaciones.
â”‚  â””â”€ ModelTraining.ipynb
â”‚      # Pruebas de modelos, comparaciÃ³n, soporte para definir la versiÃ³n final.
â”‚
â”œâ”€ src/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ etl.py
â”‚  â”‚   # Funciones reutilizables:
â”‚  â”‚   #   - Carga y limpieza de los 5 CSV.
â”‚  â”‚   #   - NormalizaciÃ³n de columnas.
â”‚  â”‚   #   - ConstrucciÃ³n del dataset unificado.
â”‚  â”œâ”€ train_model.py
â”‚  â”‚   # Script de entrenamiento final:
â”‚  â”‚   #   - Usa etl.load_unified()
â”‚  â”‚   #   - Aplica split 70/30
â”‚  â”‚   #   - Entrena LinearRegression
â”‚  â”‚   #   - Calcula mÃ©tricas
â”‚  â”‚   #   - Guarda happiness_model.pkl
â”‚  â””â”€ evaluate.py (opcional)
â”‚      # Helpers para cÃ¡lculo de mÃ©tricas fuera de lÃ­nea (si se requiere).
â”‚
â”œâ”€ docker-compose.yml
â”‚   # Define servicios de Kafka, Zookeeper y PostgreSQL.
â”‚
â”œâ”€ requirements.txt
â”‚   # Dependencias del entorno Python.
â”‚
â”œâ”€ .env
â”‚   # ConfiguraciÃ³n de conexiÃ³n (Kafka, Postgres, etc.).
â”‚
â””â”€ README.md
    # GuÃ­a rÃ¡pida de uso del proyecto.
````

---

## 3. DiseÃ±o de datos y ETL ğŸ§¹

### 3.1. Problema inicial

Los archivos de 2015â€“2019 no tienen el mismo esquema:

* Cambian nombres de columnas.
* Algunas columnas existen solo en ciertos aÃ±os.
* Hay variaciones en cÃ³mo se llama al paÃ­s, score, etc.

Ejemplos:

* `Country` vs `Country or region`
* `Happiness Score` vs `Score`
* `Economy (GDP per Capita)` vs `GDP per capita`
* `Health (Life Expectancy)` vs `Healthy life expectancy`
* `Trust (Government Corruption)` vs `Perceptions of corruption`

### 3.2. SoluciÃ³n en `src/etl.py`

`etl.py` concentra TODA la lÃ³gica de limpieza.
Esto es clave porque:

* El **EDA**, el **entrenamiento** y el **producer** usan exactamente la misma lÃ³gica.
* Evita â€œtrampaâ€ de usar datasets distintos en training vs producciÃ³n.

Pasos principales del ETL:

1. **Lectura por aÃ±o**:

   * Para cada archivo (`2015.csv`â€¦`2019.csv`) se aplica un mapeo especÃ­fico a nombres estÃ¡ndar.

2. **EstandarizaciÃ³n de columnas clave**:

   * Se construye un esquema comÃºn con las columnas:

     ```text
     Country
     Year
     Happiness Score
     GDP per capita
     Social support
     Healthy life expectancy
     Freedom
     Perceptions of corruption
     ```

3. **Tipos de datos**:

   * ConversiÃ³n a `float` para features numÃ©ricas.
   * ConversiÃ³n de `Year` a entero.
   * Filtrado de filas con nulos en las columnas clave (para el modelo).

4. **Dataset final**:

   * Se genera un DataFrame unificado `df_all` que combina 2015â€“2019 con esquema consistente.
   * Este es la base para:

     * EDA
     * Entrenamiento
     * Streaming

### 3.3. EDA (`notebooks/EDA.ipynb`)

Dentro del notebook se hace:

* Descriptivos generales (media, min, max, etc.).
* Distribuciones por feature.
* CorrelaciÃ³n entre:

  * `Happiness Score` y cada feature.
* ComparaciÃ³n por aÃ±os para ver estabilidad del comportamiento.

**DecisiÃ³n importante:**

* No se implementa winsorizaciÃ³n ni tratamiento fuerte de outliers en el pipeline final.
* Se analizan outliers en el EDA (para entenderlos), pero no se alteran los datos productivos:

  * Esto mantiene interpretabilidad.
  * Evita modificar artificialmente regiones extremas.

---

## 4. Entrenamiento del modelo ğŸ¯

### 4.1. Script: `src/train_model.py`

Responsabilidades:

1. Llama a `load_unified()` de `etl.py`.

2. Selecciona solo columnas completas en `FEATURES + TARGET`.

3. Define:

   ```python
   FEATURES = [
       "GDP per capita",
       "Social support",
       "Healthy life expectancy",
       "Freedom",
       "Perceptions of corruption",
   ]
   TARGET = "Happiness Score"
   ```

4. Aplica `train_test_split`:

   * `test_size=0.30`
   * `random_state=42` (misma semilla usada luego en el producer para marcar train/test).

5. Entrena `LinearRegression`.

6. Calcula mÃ©tricas en el **test set** (solo test, nada de mezclar train):

   * RÂ²
   * MAE
   * RMSE

7. Muestra resultados en consola con formato claro.

8. Guarda el modelo entrenado en:

   ```text
   model/happiness_model.pkl
   ```

### 4.2. JustificaciÃ³n del modelo

* La relaciÃ³n entre las variables seleccionadas y `Happiness Score` es casi lineal o monÃ³tona.
* Linear Regression:

  * Es interpretable.
  * Permite ver el peso de cada feature.
  * Es suficiente para el alcance del workshop.

---

## 5. Arquitectura de Streaming â˜ï¸

AquÃ­ conectamos todo: ETL + modelo + Kafka + Postgres.

### 5.1. Diagrama general (High-level)

```mermaid
flowchart LR
  subgraph RAW[CSV: 2015â€“2019]
    A2015[2015.csv]
    A2016[2016.csv]
    A2017[2017.csv]
    A2018[2018.csv]
    A2019[2019.csv]
  end

  RAW --> B[ETL unificado<br/>(src/etl.py)]
  B --> C[Entrenamiento<br/>(src/train_model.py)]
  C --> M[Modelo .pkl<br/>(happiness_model.pkl)]

  B --> P[Producer<br/>(kafka/producer.py)]
  M -. usado por .-> CO[Consumer<br/>(kafka/consumer.py)]

  P -- mensajes JSON --> K[(Kafka<br/>topic: happiness_features)]
  K --> CO
  CO --> DW[(PostgreSQL<br/>tabla: predictions)]

  DW --> BI[Power BI<br/>Dashboard]
```

---

## 6. Producer â€“ `kafka/producer.py` ğŸ“¤

### 6.1. Rol

El producer **simula** el flujo de datos hacia Kafka, pero respetando el mismo pipeline lÃ³gico que usamos para entrenar.

Pasos:

1. Llama `load_unified()` para construir el dataset limpio.
2. Repite internamente el `train_test_split` con la misma semilla (42) para saber:

   * QuÃ© filas son **train**.
   * QuÃ© filas son **test**.
3. Crea las columnas:

   * `is_train` (1/0)
   * `is_test` (1/0)
   * `y_true` (`Happiness Score` original).
4. Construye un JSON por fila con:

   * Identidad: `Country`, `Year`
   * Features: `GDP per capita`, `Social support`, `Healthy life expectancy`, `Freedom`, `Perceptions of corruption`
   * Metadata: `y_true`, `is_train`, `is_test`
5. EnvÃ­a cada mensaje al topic `happiness_features`.

### 6.2. Output esperado (ejemplo)

```text
[producer] using topic=happiness_features @ localhost:9092
[producer] sending records...

â†’ (France, 2018, y_true=6.489, train=1, test=0)
â†’ (Brazil, 2019, y_true=6.300, train=0, test=1)
â†’ (India, 2017, y_true=4.315, train=1, test=0)
...

[producer] done. sent=781 â†’ topic=happiness_features @ localhost:9092
```

Puntos clave:

* No lee un dataset â€œya unidoâ€ externo: Ã©l mismo ejecuta el ETL.
* Respeta el split original para que el anÃ¡lisis en el DW sea coherente.

---

## 7. Consumer â€“ `kafka/consumer.py` ğŸ“¥

### 7.1. Rol

El consumer es quien convierte el stream en algo Ãºtil:

1. Escucha el topic `happiness_features`.
2. Por cada mensaje:

   * Extrae las features.
   * Carga el modelo `happiness_model.pkl` (al inicio).
   * Calcula `y_pred` usando las mismas columnas que en el entrenamiento.
3. Inserta el registro en PostgreSQL en la tabla `predictions` usando:

   * `INSERT ... ON CONFLICT ... DO UPDATE`
     (para no duplicar cuando se reenvÃ­an los mismos datos).

### 7.2. Esquema de la tabla `predictions` en PostgreSQL

```sql
CREATE TABLE IF NOT EXISTS predictions (
    country   TEXT    NOT NULL,
    year      INTEGER NOT NULL,
    gdp       REAL,
    social    REAL,
    health    REAL,
    freedom   REAL,
    corrupt   REAL,
    y_true    REAL,
    is_train  INTEGER,
    is_test   INTEGER,
    y_pred    REAL,
    UNIQUE(country, year, is_train, is_test)
);
```

* La clave Ãºnica garantiza:

  * Si se vuelve a correr el pipeline, no se duplican filas.
  * Cada combinaciÃ³n paÃ­s-aÃ±o-split aparece una sola vez.

### 7.3. LÃ³gica interna resumida

* Deserializa el JSON del mensaje.
* Ordena las features correctamente.
* `model.predict(X)` â†’ `y_pred`.
* Construye un `INSERT` con UPSERT.
* Muestra en consola un resumen legible (paÃ­s, aÃ±o, flags, valores).

Ejemplo de log:

```text
[consumer] ready
  â€¢ topic:      happiness_features
  â€¢ bootstrap:  localhost:9092
  â€¢ group_id:   workshop3-consumer
  â€¢ model:      model/happiness_model.pkl
  â€¢ postgres:   workshop@localhost:5432/workshop3
  â€¢ table:      predictions
--------------------------------------------------------------
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ France (2018)                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚y_true: 6.489    y_pred: 6.402                               â”‚
â”‚train: 1    test: 0                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
...
âœ” finished. total_upserted=781
```

---

## 8. EvaluaciÃ³n del modelo desde el Data Warehouse ğŸ“ˆ

Con todo en `predictions`, podemos evaluar el modelo **directamente en PostgreSQL** o desde Power BI filtrando:

* **Entrenamiento:** `is_train = 1`
* **Prueba:** `is_test = 1`

### 8.1. Ejemplos de consultas SQL (lado servidor)

**MÃ©tricas globales en test:**

```sql
SELECT
    COUNT(*)                           AS n,
    AVG(ABS(y_true - y_pred))          AS mae,
    SQRT(AVG(POWER(y_true - y_pred,2))) AS rmse
FROM predictions
WHERE is_test = 1;
```

**RÂ² global en test:**

```sql
WITH stats AS (
    SELECT
        AVG(y_true) AS y_mean
    FROM predictions
    WHERE is_test = 1
),
errs AS (
    SELECT
        (y_true - y_pred)               AS err,
        (y_true - (SELECT y_mean FROM stats)) AS dev
    FROM predictions
    WHERE is_test = 1
)
SELECT
    1 - SUM(POWER(err,2)) / NULLIF(SUM(POWER(dev,2)),0) AS r2
FROM errs;
```

**KPIs por aÃ±o (solo test):**

```sql
WITH base AS (
    SELECT
        year,
        y_true,
        y_pred
    FROM predictions
    WHERE is_test = 1
)
SELECT
    year,
    COUNT(*)                                 AS n,
    AVG(ABS(y_true - y_pred))                AS mae,
    SQRT(AVG(POWER(y_true - y_pred,2)))      AS rmse
FROM base
GROUP BY year
ORDER BY year;
```

**Top 10 errores (solo test):**

```sql
SELECT
    country,
    year,
    y_true,
    y_pred,
    ABS(y_true - y_pred) AS abs_error
FROM predictions
WHERE is_test = 1
ORDER BY abs_error DESC
LIMIT 10;
```

Estos resultados alimentan directamente el anÃ¡lisis y el dashboard.

---

## 9. Dashboard (Power BI) â€“ Vista conceptual ğŸ¨

El dashboard se construye sobre la tabla `predictions` en PostgreSQL.

### PÃ¡gina 1 â€“ Entrenamiento & Datos

* Card: `Total registros`
* Card: `Registros train`
* Card: `Registros test`
* Bar chart:

  * Eje X: `year`
  * Valores: cantidad train/test
* Scatter:

  * X: `GDP per capita`
  * Y: `y_true`
  * Filtro: `is_train = 1`
  * Objetivo: mostrar con quÃ© datos se entrenÃ³ el modelo.

### PÃ¡gina 2 â€“ Performance del Modelo (Test)

* Cards:

  * `RÂ² test`, `MAE test`, `RMSE test`
* Scatter:

  * X: `y_pred`
  * Y: `y_true`
  * Filtro: `is_test = 1`
  * Para ver quÃ© tan cerca estamos de la diagonal perfecta.
* Tabla o bar chart:

  * Top paÃ­ses con mayor error absoluto (solo test).

Con esto el profesor ve:

* Que el modelo se entrenÃ³ correctamente.
* Que la evaluaciÃ³n usa Ãºnicamente datos de prueba.
* Que la arquitectura conecta todo: CSV â†’ ETL â†’ Modelo â†’ Kafka â†’ Postgres â†’ BI.

---

## 10. Conclusiones âœ…

* Se implementÃ³ un flujo **consistente y reproducible**:

  * Misma lÃ³gica de ETL para EDA, entrenamiento y streaming.
  * Modelo simple pero interpretable.
  * SeparaciÃ³n clara entre datos de entrenamiento y prueba mediante flags en el DW.
* Kafka y PostgreSQL permiten simular un escenario real:

  * Streaming de datos.
  * AplicaciÃ³n de modelo en lÃ­nea.
  * Persistencia centralizada.
* El Data Warehouse expone una sola tabla (`predictions`) desde la cual:

  * Se pueden calcular KPIs del modelo.
  * Se construyen dashboards limpios y defendibles.

Este documento sirve como respaldo tÃ©cnico del proyecto para revisiÃ³n acadÃ©mica o profesional.